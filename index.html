<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>RoboMP2: A Robotic Multimodal Perception-Planning Framework with Mutlimodal Large Language Models</title>

    <style>
        /* 使用CSS设置字体样式 */
        .times-font {
            font-family: "Times New Roman", Times, serif;
        }
        .image-container {
            width: 65%; /* 设置容器宽度为图片宽度的65% */
            margin: 10px auto; /* 设置左右边距为 auto，实现居中对齐 */
        }

        .image-container img {
            width: 85%; /* 让图片宽度占据整个容器的宽度 */
            display: block; /* 使图片成为一个块级元素，避免与其他元素同行 */
        }
        .video-container {
            display: flex; /* 使用 Flexbox 布局 */
            justify-content: space-between; /* 将视频之间的空间平均分配 */
        }

        .video-item {
            text-align: center; /* 视频和标题居中对齐 */
            width: 23%; /* 设置每个视频容器的宽度为四分之一 */
        }

        .video-item video {
            width: 100%; /* 视频宽度设置为100%，以填充其父容器的宽度 */
        }

        .video-caption {
            margin-top: 10px; /* 设置标题与视频之间的上边距 */
        }

    </style>
    <script>
        var task_map = {
            "simple-object-manipulation": "simple_object_manipulation",
            "visual-goal-reaching": "visual_goal_reaching",
            "novel-concept-grounding": "novel_concept_grounding",
            "one-shot-video-imitation": "one_shot_video_imitation",
            "visual-constraint-satisfaction": "visual_constraint_satisfaction",
            "visual-reasoning": "visual_reasoning"
        };

        function updateDemoVideo(category) {
            // var demo = document.getElementById("single-menu-demos").value;
            var task = document.getElementById(category + "-menu-tasks").value;
            var inst = document.getElementById(category + "-menu-instances").value;

            console.log(task_map[category], task, inst)

            var video = document.getElementById(category + "-single-task-video");
            video.src = "assets/videos/demos/" +
                task_map[category] +
                "/" +
                task +
                "/" +
                inst +
                ".mp4";
            video.playbackRate = 2.0;
            video.play();
        }
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="./static/css/academicons.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">RoboMP<sup>2</sup>: A Robotic Multimodal Perception-Planning Framework with Multimodal Large Language Models</h1>
                    <!-- <h3 class="title is-4 conference-authors"><a target="_blank" href="https://icml.cc/">ICML 2023</a> -->
                    </h3>
                    <div class="is-size-5 publication-authors">
            <span class="author-block">
                <a target="_blank" href="https://aopolin-lv.github.io/">Qi&#160;Lv</a><sup>12</sup>,
                <a target="_blank" href="https://openreview.net/profile?id=~Hao_Li59">Hao&#160;Li</a><sup>1</sup>,
                <a target="_blank"
                   href="https://xiang-deng-dl.github.io/">Xiang&#160;Deng</a><sup>1</sup>,
                <a target="_blank" href="https://rshaojimmy.github.io/">Rui&#160;Shao</a><sup>1</sup>,
                <a target="_blank" href="https://scholar.google.com/citations?user=Oo7c22wAAAAJ&hl=zh-CN">Michael&#160;Yu&#160;Wang</a><sup>2</sup>,
                <a target="_blank"
                   href="https://liqiangnie.github.io/">Liqiang&#160;Nie</a><sup>1</sup>
            </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>Harbin Institute of Technology, Shenzhen; </span>
                        <span class="author-block"><sup>2</sup>Great Bay University </span>
                    </div>

                    <!-- <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>&dagger;</sup>Equal Contribution</span>
                        <span class="author-block"><sup>&#8225;</sup>Equal Advising </span> -->
                    <!-- </div> -->

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- TODO PDF Link. -->
                            <span class="link-block">
                <a target="_blank" href="https://arxiv.org/abs/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                            <span class="link-block">
                <a target="_blank" href="assets/RoboMP2.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
              </span>
                            <!-- Code Link. -->
                            <span class="link-block">
                <a target="_blank" href="https://aopolin-lv.github.io/RoboMP2.github.io/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                </a>
                <!-- <a target="_blank" href="https://github.com/vimalabs/VIMA#pretrained-models"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa fa-network-wired"></i>
                  </span>
                  <span>Models</span>
                </a> -->
                <!-- <a target="_blank" href="https://github.com/vimalabs/VimaBench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-robot"></i>
                  </span>
                  <span>Benchmark</span>
                </a>
                <a target="_blank" href="https://huggingface.co/datasets/VIMA/VIMA-Data"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>Dataset</span>
                </a> -->
              </span>
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="section">
    <div class="container is-max-widescreen">
        <div class="rows">
            <div class="rows is-centered ">
                <div class="row is-full-width">
                    <img src="assets/images/intro_1.png" class="interpolation-image"
                         alt="" style="display: block; margin-left: 10px; margin-right: auto"/>
                    <span style="font-size: 110%"><i>The left</i>: The detection results of the yellow block with the complex spatial reference using different methods. <i>The right</i>: Different plans for different environment, even if the same instruction.</span>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p style="font-size: 125%">
                        Multimodal Large Language Models (MLLMs) have shown impressive reasoning abilities and general 
                        intelligence in various domains. It inspires researchers to train end-to-end MLLMs or utilize 
                        large models to generate policies with human-selected prompts for embodied agents. However, 
                        these methods exhibit limited generalization capabilities on unseen tasks or scenarios, and 
                        overlook the multimodal environment information which is critical for robots to make decisions.
                        In this paper, we introduce a novel <b>Robo</b>tic <b>M</b>ultimodal <b>P</b>erception-<b>P</b>lanning
                        (<b>RoboMP<sup>2</sup></b>) framework for robotic manipulation which consists of a Goal-Conditioned 
                        Multimodal Preceptor (GCMP) and a Retrieval-Augmented Multimodal Planner (RAMP). Specially, GCMP 
                        captures environment states by employing a tailored MLLMs for embodied agents with the abilities of 
                        semantic reasoning and localization. RAMP utilizes coarse-to-fine retrieval method to find the <span class="times-font">k</span>
                        most-relevant policies as in-context demonstrations to enhance the planner. Extensive experiments 
                        demonstrate the superiority of RoboMP<sup>2</sup>on both VIMA benchmark and real-world tasks, with around 
                        10% improvement over the baselines.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="section">
    <div class="container is-max-widescreen">
        <div class="rows">
            <div class="rows is-centered ">
                <h2 class="title is-3"><span
                        class="dvima">Overview of our proposed RoboMP<sup>2</sup></span></h2>
                <br>
                <div class="row is-full-width">
                    <img src="assets/images/RoboMP2_framework.png" class="interpolation-image"
                         alt="" style="display: block; margin-left: auto; margin-right: auto"/>
                    <br>
                    <span style="font-size: 110%">The three parts in grey/blue/green represent the input data, planning and
                        perception, respectively. The modules highlighted are trainable, including fusion module and LoRA.</span>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-widescreen">

        <div class="rows">
            <div class="rows is-centered ">
                <div class="row is-full-width">
                    <h2 class="title is-3"><span
                            class="dvima">Demo</span></h2>
                    <br>
                    <h3 class="title is-4"><span class="dvima">Simulation</span></h3>
                    <div class="video-container">
                        <div class="video-iterm">
                            <video control muted autoplay loop width="93%">
                                <source src="assets/videos/demos/simulation/manipulate_old_neighbor.mp4" type="video/mp4">
                            </video>
                            <figcaption class="video-caption">First put the brick block into the red swirl pan then put the object that was previously at its east into the same object.</figcaption>
                        </div>
                        <div class="video-iterm">
                            <video control muted autoplay loop width="93%">
                                <source src="assets/videos/demos/simulation/same_shape.mp4" type="video/mp4">
                            </video>
                            <figcaption class="video-caption">Put all objects with the same profile as the blue and purple polka dot frame into it.</figcaption>
                        </div>
                        <div class="video-iterm">
                            <video control muted autoplay loop width="93%">
                                <source src="assets/videos/demos/simulation/pick_in_order_then_restore.mp4" type="video/mp4">
                            </video>
                            <figcaption class="video-caption">Put the yellow and green stripe round into the pink pallet then the yellow paisley pallet. Finally restore it into its original container.</figcaption>
                        </div>
                        <div class="video-iterm">
                            <video control muted autoplay loop width="93%">
                                <source src="assets/videos/demos/simulation/sweep.mp4" type="video/mp4">
                            </video>
                            <figcaption class="video-caption">Sweeping any yellow and blue stripe blocks into the green and blue stripe three-sided rectangle without exceeding the polka dot line.</figcaption>
                        </div>
                    </div>
                    <br>
                    <h3 class="title is-4"><span class="dvima">Real-World</span></h3>
                    <div class="video-container">
                        <div class="video-iterm">
                            <video control muted autoplay loop width="93%">
                                <source src="assets/videos/demos/real-world/Pick_in_order.mp4" type="video/mp4">
                            </video>
                            <figcaption class="video-caption">Put the yellow block into the green plate then the pink bowl. Finally restore it into its original position</figcaption>
                        </div>
                        <div class="video-iterm">
                            <video control muted autoplay loop width="93%">
                                <source src="assets/videos/demos/real-world/Rearrange.mp4" type="video/mp4">
                            </video>
                            <figcaption class="video-caption">Put any vegetables into the pink bowl and any fruits into the green plate.</figcaption>
                        </div>
                        <div class="video-iterm">
                            <video control muted autoplay loop width="93%">
                                <source src="assets/videos/demos/real-world/Tool.mp4" type="video/mp4">
                            </video>
                            <figcaption class="video-caption">Hand over the object which can repair the TV.</figcaption>
                        </div>
                        <div class="video-iterm">
                            <video control muted autoplay loop width="93%">
                                <source src="assets/videos/demos/real-world/Distraction.mp4" type="video/mp4">
                            </video>
                            <figcaption class="video-caption">Put any yellow blocks into the green plate.</figcaption>
                        </div>
                    </div>
                </div>
            </div>

        </div>
    </div>
</section>

<section class="hero-body">
    <div class="container is-max-widescreen">
        <div class="rows">
            <div class="rows is-centered ">
                <div class="row is-full-width">
                    <h2 class="title is-3"><span
                        class="dvima">Qualitative Results</span></h2>
                    <br>
                    <img src="assets/images/Visualization.png" class="interpolation-image"
                         alt="" style="display: block; margin-left: auto; margin-right: auto"/>
                    <br>
                    <!-- <span style="font-size: 110%"><b>Overview of our proposed RoboMP<sup>2</sup>.</b> he three parts in grey/blue/green represent the input data, planning and
                        perception, respectively. The modules highlighted are trainable, including fusion module and LoRA.</span> -->
                </div>
            </div>
        </div>
    </div>
</section>

<!--Experiments-->
<section class="section">
    <div class="container is-max-widescreen">
        <div class="rows">
            <div class="rows is-centered ">
                <div class="row is-full-width">
                    <h2 class="title is-3"><span
                            class="dvima">Experiments</span></h2>            
                    <br>
                    <h3 class="title is-4"><span
                            class="dvima">Results on VIMABench tasks and real-world tasks</span></h3>

                    <img src="assets/images/Results.png" class="interpolation-image"
                         alt="" style="display: block; margin-left: auto; margin-right: auto" width="90%"/>
                    <br>
                    <br>
                    <h3 class="title is-4"><span
                            class="dvima">Ablation Studies </span></h3>

                    <img src="assets/images/Ablation.png" class="interpolation-image"
                         alt="" style="display: block; margin-left: auto; margin-right: auto" width="90%"/>
                    <br>
                </div>
            </div>

        </div>
    </div>
</section>

<!--Conclusion-->
<section class="section">
    <div class="container is-max-widescreen">
        <div class="rows">
            <div class="rows is-centered ">
                <div class="row is-full-width">
                    <h2 class="title is-3"><span
                            class="dvima">Conclusion</span></h2>

                    <p style="font-size: 125%">
                        In this paper, we have proposed a novel Robotic Perception and Planning framework (RoboMP<sup>2</sup>) that consists of the
                        Goal-Conditioned Multimodal Perceptor (GCMP) and the Retrieval-Augmented Multimodal Planner (RAMP). GCMP
                        is introduced to capture multimodal environment information by incorporating a tailored MLLM. RAMP employs a
                        coarse-to-fine retrieval-augmented approach to adapatively
                        select the <i><span class="times-font">k</span></i> most-relevant policies as in-context demonstrations to enhance the generalization. Extensive experiments
                        demonstrate that RoboMP<sup>2</sup> outperforms the baselines by a large margin on both VIMABench and real-world tasks.
                    </p>

                </div>
            </div>

        </div>
    </div>
</section>


<section class="section" id="BibTeX">
    <div class="container is-max-widescreen content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{lv2024robomp2,
  title     = {RoboMP$2^$: A Robotic Multimodal Perception-Planning Framework with Multimodal Large Language Models},
  author    = {Qi Lv, Hao Li, Xiang Deng, Rui Shao, Michael Yu Wang, Liqiang Nie},
  year      = {2024}
}</code></pre>
    </div>
</section>

<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column">
                <div class="content has-text-centered">
                    <p>
                        Website template borrowed from <a
                            href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> and <a
                            href="https://github.com/vimalabs/vimalabs.github.io">VIMA</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>